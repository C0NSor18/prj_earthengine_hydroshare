{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Supervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**\n",
    "The purpose of this lab is introduce you to concepts of supervised classification and regression: prediction of nominal or numeric values of a geographic variable from other geographic variables.  You will explore processes of training data collection, classifier selection, classifier training, image classification and accuracy assessment.  At the completion of the lab, you will be able to perform supervised classification and regression in Earth Engine.\n",
    "\n",
    "**Prerequisites:** Lab 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to classification and regression\n",
    "For present purposes, define prediction as guessing the value of some geographic variable of interest *g*, using a function *G* that takes as input a pixel vector **p**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "G_{T}(p_i) = g_i \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *i* in this equation refers to a particular instance from a set of pixels.  Think of *G* as a guessing function and *gi* as the guess for pixel *i*.   The **T** in the subscript of *G* refers to a *training set* (a set of known values for p and the correct g), used to infer the structure of G.  You have to choose a suitable *G* to train with **T**.  When *g* is nominal (e.g. {'water', 'vegetation', 'bare'}), call this setup classification.  When g is numeric, call this setup regression.  This is an incredibly simplistic description of a problem addressed in a broad range of fields including mathematics, statistics, data mining, machine learning, etc.  Interested readers may see [Witten et al. (2011)](http://www.cs.waikato.ac.nz/ml/weka/book.html), [Hastie et al. (2009)](http://statweb.stanford.edu/~tibs/ElemStatLearn/) or [Goodfellow et al (2016)](http://www.deeplearningbook.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Classification in Earth Engine has a similar workflow to regression: build the training, train the classifier, classify an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification, g is nominal.  The first step is to create training data manually.  (Alternatively, upload a shapefile  training data, for example data collected on the ground with a GPS).  Using the geometry tools and the Landsat composite as a background, digitize training polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6da7077b2040b398aba909d405eef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[0, 0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_text'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cbd47ae3b1469881cecedb6027e231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(CustomInspector(children=(SelectMultiple(options=OrderedDict(), value=()), Accordion(selected_in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initializing display and earthengine\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "# importing ipygee for dynamic mapping\n",
    "from ipygee import *\n",
    "\n",
    "Map = Map() # from ipygee\n",
    "Map.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import data to use as predictor variables (**p**).  Search 'landsat 5 raw' and import 'USGS Landsat 5 TM Collection 1 Tier 1 Raw Scenes'.  Name the import l5raw.  Filter by time and the [WRS-2](http://landsat.usgs.gov/worldwide_reference_system_WRS.php) path and row to get only scenes over the San Francisco bay area in 2010:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5raw = ee.ImageCollection(\"LANDSAT/LT05/C01/T1\")\n",
    "\n",
    "l5filtered = l5raw.filterDate('2010-05-01', '2010-10-31').\\\n",
    "filterMetadata('WRS_PATH', 'equals', 44).\\\n",
    "filterMetadata('WRS_ROW', 'equals', 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an Earth Engine algorithm to get a cloud-free composite of Landsat imagery in 2010. Also apply the *waterMask* mask to the *landsat* composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat = ee.Algorithms.Landsat.simpleComposite(l5filtered,50,10,40, True)\n",
    "\n",
    "# landsat = landsat.updateMask(waterMask)\n",
    "# print(landsat.getInfo())\n",
    "Map.addLayer(landsat, {'bands': ['B4', 'B3', 'B2'], 'max': 0.3}, 'False color composite')\n",
    "\n",
    "Map.centerObject(l5filtered.first().geometry()) #centering the map to landsat scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define areas that have unique characteristics: bare soil, water, vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR BARE SOIL\n",
    "\n",
    "# // Create an ee.Geometry.\n",
    "polygon = ee.Geometry.Polygon([\n",
    "  [-121.40712297571075, 37.56889802091393],\n",
    "                  [-121.3589821556879, 37.60458306785724],\n",
    "                  [-121.40122078520008, 37.632091614754096],\n",
    "                  [-121.4451522325709, 37.59470036844799]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "baresoil = ee.Feature(polygon, {'class': 2, 'name': 'bare soil'});\n",
    "Map.addLayer(baresoil, {'fill_color':'yellow', 'outline': 1}, name='baresoil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR WATER\n",
    "\n",
    "# // Create an ee.Geometry.\n",
    "polygon = ee.Geometry.Polygon([\n",
    "  [-122.29352127796642, 37.628407836628305],\n",
    "                  [-122.24438118330467, 37.62657785783453],\n",
    "                  [-122.24487372817406, 37.70239874181069],\n",
    "                  [-122.2845461985611, 37.70214483298362],\n",
    "                  [-122.28727867010316, 37.70257427564966]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "water = ee.Feature(polygon, {'class': 0, 'name': 'water'});\n",
    "Map.addLayer(water, {'fill_color':'blue', 'outline': 1}, name='water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR VEGETATION\n",
    "\n",
    "# // Create an ee.Geometry.\n",
    "polygon = ee.Geometry.Polygon([\n",
    "   [-122.27066384566398, 37.21535980084099],\n",
    "                  [-122.240411435295, 37.21551898615349],\n",
    "                  [-122.23457428064451, 37.21555749104616],\n",
    "                  [-122.2348877480857, 37.266699693082586],\n",
    "                  [-122.27182604621504, 37.26835792213439]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "vegetation = ee.Feature(polygon, {'class': 1, 'name': 'vegetation'});\n",
    "Map.addLayer(vegetation, {'fill_color':'green', 'outline': 1}, name='vegetation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Features into a Feature Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFeatures = ee.FeatureCollection([water, vegetation, baresoil])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the bands of the Landsat composite to be used as predictors (i.e. the elements of p):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionBands = ['B1', 'B2', 'B3', 'B4', 'B5' ,'B7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the merged FeatureCollection, each Feature should have a property called 'class' where the classes are consecutive integers, one for each class, starting at 0.  Verify that this is true.  Create a training set T for the classifier by sampling the Landsat composite with the merged features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierTraining = landsat.select(predictionBands).sampleRegions(\n",
    "      collection= trainingFeatures, \n",
    "      properties= ['class'], \n",
    "      scale= 30\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Randomly split the data into 60% for training, and 40% for testing\n",
    "trainingTesting = classifierTraining.randomColumn('random',111009);\n",
    "\n",
    "training = trainingTesting.filter(ee.Filter.lt('random', 0.6));\n",
    "\n",
    "testing = trainingTesting.filter(ee.Filter.gte('random', 0.6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Non-linear regression functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the garden variety linear regression isn't satisfactory, Earth Engine contains other functions that can make predictions of a continuous variable.  Unlike linear regression, other regression functions are implemented by the classifier library.  \n",
    "\n",
    "- For example, a Classification and Regression Tree (CART, see Brieman et al. 1984) is a machine learning algorithm that can learn non-linear patterns in your data.  Reusing the T table (without the constant term), train a CART as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartclassifier = ee.Classifier.cart(randomSeed=111009).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make predictions over the input imagery (classify in this context is a misnomer):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartClasifficationImage = landsat.select(predictionBands).classify(cartclassifier);\n",
    "\n",
    "Map.addLayer(cartClasifficationImage, {'min': 0, 'max': 2,\n",
    "                                   'palette':['blue', 'green','yellow']},'CART classification');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example https://code.earthengine.google.com/ade42831c23ae03ab9b26289d89b31f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfClassification = ee.Classifier.smileRandomForest(numberOfTrees=1, seed=111009).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the RF regression on the landsat image\n",
    "rfClassificationImage = landsat.select(predictionBands).classify(rfClassification);\n",
    "    \n",
    "# // Visualize the RF regression\n",
    "Map.addLayer(rfClassificationImage,  {'min': 0, 'max': 2,\n",
    "                                   'palette':['blue','green', 'yellow']}, 'RF classification');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee.Classifier.libsvm(decisionProcedure, svmType, kernelType, shrinking, degree, gamma, coef0, cost, nu, terminationEpsilon, lossEpsilon, oneClass)\n",
    "\n",
    "# // Create an SVM classifier with custom parameters.\n",
    "svClassification = ee.Classifier.libsvm(kernelType='RBF',gamma=1,cost=100).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the RF regression on the landsat image\n",
    "svClassificationImage = landsat.select(predictionBands).classify(svClassification);\n",
    "    \n",
    "# // Visualize the RF regression\n",
    "Map.addLayer(svClassificationImage,{'min': 0, 'max': 2,\n",
    "                                   'palette':['blue', 'green','yellow']}, 'SV CLassification');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classification context, accuracy measurements are often derived from a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.\tPrint the confusion matrix and expand the object to inspect the matrix.  The entries represent number of pixels.  Items on the diagonal represent correct classification.  Items off the diagonal are misclassifications, where the class in row i is classified as column j.  It's also possible to get basic descriptive statistics from the confusion matrix.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the CART classification on the test set\n",
    "\n",
    "test=testing.classify(cartclassifier)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix\n",
      "[[18814     0     0]\n",
      " [    0 10640     3]\n",
      " [    0     2 14777]]\n",
      "Overall Accuracy: 0.9998869698887783\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the RF regression on the test set\n",
    "\n",
    "test=testing.classify(rfClassification)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');\n",
    "\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the SVR regression on the test set\n",
    "\n",
    "test=testing.classify(svClassification)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');\n",
    "\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Hyperparameters tuning\n",
    "\n",
    "A random forest is a collection of random trees the predictions of which are used to compute an average (regression) or vote on a label (classification).  Note that the only parameter to the classifier is the number of trees (10).  How many trees should you use?  Making that choice is best done by hyperparameter tuning.  For example, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrees = ee.List.sequence(1, 50, 1)\n",
    "\n",
    "\n",
    "def trees(t):\n",
    "    rfclass = ee.Classifier.smileRandomForest(numberOfTrees=t, seed=111009).train(\n",
    "    features= training, \n",
    "    classProperty= 'class', \n",
    "    inputProperties= predictionBands)\n",
    "    \n",
    "    rfTesting = testing.classify(rfclass)\n",
    "    testAccuracy = rfTesting.errorMatrix('class', 'classification');\n",
    "    accuracy= testAccuracy.accuracy();       \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "accuracy_trees=numTrees.map(trees)\n",
    "value_info = accuracy_trees.getInfo()\n",
    "\n",
    "# print(rmse_trees.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['Accuracy'])\n",
    "df['numTrees'] = numTrees.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='numTrees', \n",
    "             y='Accuracy',\n",
    "             title= 'Impact of Number of Trees in Random Forest'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_vals = ee.List.sequence(1, 100, 5)\n",
    "\n",
    "\n",
    "def gammas(t):\n",
    "    svclass = ee.Classifier.libsvm(kernelType='RBF',gamma=t,cost=1).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )\n",
    "    \n",
    "    svTesting = testing.classify(svclass)\n",
    "    testAccuracy = svTesting.errorMatrix('class', 'classification');\n",
    "    accuracy= testAccuracy.accuracy();       \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "accuracy_gama=gamma_vals.map(gammas)\n",
    "value_info = accuracy_gama.getInfo()\n",
    "\n",
    "# print(rmse_gama.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['Accuracy'])\n",
    "df['Gamma'] = gamma_vals.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='Gamma', \n",
    "             y='Accuracy',\n",
    "             title= 'Impact of Gamma in SVR'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "Recreate this notebook for Florida, a humid climate with a variety of forest (natural to agriculture). Make sure your SVR and Random Forest uses the tuned hyperparameters when discussing your RMSE found. Are the 4 models behaving similarly? Do they statistically perform different than this example? Discuss it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
